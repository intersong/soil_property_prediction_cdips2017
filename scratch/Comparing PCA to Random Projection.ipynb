{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing PCA Dimensionality Reduction to Random Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import random_projection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the\n",
    "[Dimensionality Reduction Notebook](./Dimensionality\\ Reduction.ipynb),\n",
    "we were motivated to reduce the length of our data vectors because we had more data dimensions than we had observations, leading to\n",
    "[overfitting](./Cross\\ Validation\\ Example.ipynb).\n",
    "\n",
    "The first choice for reducing dimensions is PCA, as described in detail in the\n",
    "[Dimensionality Reduction Notebook](./Dimensionality\\ Reduction.ipynb).\n",
    "\n",
    "Though PCA has a rigorous justification in terms of information-maximizing transforms, the assumptions that would guarantee that PCA was the right choice don't hold in our (and most real-life) case.\n",
    "\n",
    "This notebook compares PCA to what you might think would be an overly-simple model:\n",
    "[random projection](https://en.wikipedia.org/wiki/Random_projection).\n",
    "In random projection, instead of carefully selecting the vectors onto which we project our data,\n",
    "we select them at random according to some distribution.\n",
    "The most common choice is a Gaussian distribution.\n",
    "\n",
    "Below, we run\n",
    "[cross-validaiton](./Cross\\ Validation\\ Example.ipynb)\n",
    "to determine the performance of randomly-chosen projections of\n",
    "size ranging from one dimension to as many dimensions as we have data points.\n",
    "\n",
    "Perhaps surprisingly, there doesn't seem to be any difference in performance on the test set between\n",
    "random projections and projections onto the principal components!\n",
    "Furthermore, we need our components to retain roughly 99% of the variance \n",
    "This would seem to indicate that the directions of large variance in our input data\n",
    "are not the directions of variability that are useful for predicting our targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runCV(num_splits,transforms,X,y,model):\n",
    "    \n",
    "    train_scores = np.zeros((num_splits,len(transforms)))\n",
    "    test_scores = np.zeros((num_splits,len(transforms)))\n",
    "\n",
    "    for transform_idx, transform in enumerate(transforms):\n",
    "\n",
    "        for split_idx in range(num_splits):\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.2,)\n",
    "\n",
    "            transformed_X_train = transform.transform(X_train)\n",
    "            transformed_X_test =  transform.transform(X_test)\n",
    "\n",
    "            model.fit(transformed_X_train,y_train)\n",
    "\n",
    "            train_score = model.score(transformed_X_train,y_train)\n",
    "            test_score = model.score(transformed_X_test,y_test)\n",
    "\n",
    "            train_scores[split_idx,transform_idx] = train_score\n",
    "            test_scores[split_idx,transform_idx] = test_score\n",
    "            \n",
    "    return train_scores, test_scores\n",
    "\n",
    "def transformsFromSchedule(to_keep_schedule,X,transform_type=\"\"):\n",
    "    \n",
    "    transforms = []\n",
    "    \n",
    "    if transform_type == \"PCA\":\n",
    "        transform = PCA\n",
    "    elif transform_type == \"random\":\n",
    "        transform = random_projection.GaussianRandomProjection\n",
    "    else:\n",
    "        raise ValueError(\"unknown transform \"+transform_type)\n",
    "    \n",
    "    for to_keep in to_keep_schedule:\n",
    "        transforms.append(transform(n_components=to_keep).fit(X))\n",
    "    \n",
    "    return transforms\n",
    "\n",
    "def plotCV(schedule,train_scores,test_scores,transform_type):\n",
    "    mean_train_scores = np.mean(train_scores,axis=0)\n",
    "    mean_test_scores = np.mean(test_scores,axis=0)\n",
    "\n",
    "    sd_train_scores = np.std(train_scores,axis=0,ddof=1)\n",
    "    sd_test_scores = np.std(test_scores,axis=0,ddof=1)\n",
    "\n",
    "    plt.errorbar(schedule,mean_train_scores,\n",
    "                     yerr=sd_train_scores,\n",
    "                 linewidth=4,alpha=0.75,\n",
    "                 label=transform_type+'-Train',\n",
    "                )\n",
    "\n",
    "    plt.errorbar(schedule,mean_test_scores,\n",
    "                     yerr=sd_test_scores,\n",
    "                 linewidth=4,alpha=0.75,\n",
    "                 label=transform_type+'-Test',\n",
    "                linestyle='--')\n",
    "\n",
    "def makePlot(schedule,train_scores,test_scores,transform_type=\"PCA\"):\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.set_xscale(\"log\", nonposx='clip')\n",
    "    \n",
    "    plotCV(schedule,train_scores,test_scores,transform_type)\n",
    "    \n",
    "    plt.ylim([0,1]);\n",
    "\n",
    "    plt.xlabel(\"Retained Dimensions\");\n",
    "    plt.ylabel(\"$R^2$\")\n",
    "    plt.legend(); plt.title(\"Train vs. Test Scores for \" +transform_type+ \"-DR\");\n",
    "    \n",
    "def getBest(test_scores,to_keep_schedule):\n",
    "    \n",
    "    mean_test_scores = np.mean(test_scores,axis=0)\n",
    "    \n",
    "    best_score_index = np.argmax(mean_test_scores)\n",
    "    best_score = mean_test_scores[best_score_index]\n",
    "    best_score_num_dimensions = to_keep_schedule[best_score_index]\n",
    "    print(\"the best number of dimensions to keep is: \"+ str(best_score_num_dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produceCVPlot(to_keep_schedule,num_splits,\n",
    "                  X,y,\n",
    "                  model=skl.linear_model.LinearRegression(),\n",
    "                 transform_type=\"PCA\"):\n",
    "    \n",
    "    transforms = transformsFromSchedule(to_keep_schedule,X,transform_type=transform_type)\n",
    "    \n",
    "    train_scores, test_scores = runCV(num_splits,transforms,X,y,model)\n",
    "    \n",
    "    makePlot(to_keep_schedule,train_scores,test_scores,transform_type=transform_type)\n",
    "    getBest(test_scores,to_keep_schedule)\n",
    "    \n",
    "    return train_scores,test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/training.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_columns = [column for column in train.columns if column.startswith('m')]\n",
    "wavenumbers = [float(column.lstrip('m')) for column in data_columns]\n",
    "\n",
    "output_columns = [\"Ca\",\"P\",\"pH\",\"SOC\",\"Sand\"]\n",
    "\n",
    "X = train[data_columns].as_matrix()\n",
    "y = train[output_columns].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep_schedule = [1,2,3,4,5,6,7,8,9,\n",
    "                    10,20,30,50,\n",
    "                    100,200,\n",
    "                    1157,\n",
    "                   ]\n",
    "num_splits = 20\n",
    "PCA_train_scores, PCA_test_scores = produceCVPlot(to_keep_schedule,num_splits,\n",
    "             X,y,\n",
    "             );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep_schedule = [1,2,3,4,5,6,7,8,9,\n",
    "                    10,20,30,50,\n",
    "                    100,200,\n",
    "                    1157,\n",
    "                   ]\n",
    "num_splits = 20\n",
    "\n",
    "random_train_scores, random_test_scores = produceCVPlot(to_keep_schedule,num_splits,\n",
    "             X,y,transform_type=\"random\"\n",
    "             );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking Closer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be a substantial difference between the performance of PCA and Gaussian-Random dimensionality reduction only at low numbers of retained dimensions. The cell below examines this more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_up_to = 10\n",
    "sub_schedule = to_keep_schedule[:keep_up_to];\n",
    "plt.figure(figsize=(12,4))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plotCV(sub_schedule,\n",
    "       PCA_train_scores[:,:keep_up_to],PCA_test_scores[:,:keep_up_to],\n",
    "       transform_type=\"PCA\")\n",
    "\n",
    "plotCV(sub_schedule,\n",
    "       random_train_scores[:,:keep_up_to],random_test_scores[:,:keep_up_to],\n",
    "       transform_type=\"random\")\n",
    "\n",
    "plt.ylim([0,1]); plt.legend(); plt.title(\"Train and Test Scores for PCA and Random DR\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

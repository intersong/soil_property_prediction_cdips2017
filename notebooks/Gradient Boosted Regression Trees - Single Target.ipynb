{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "import scripts.load_data as load\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "import sklearn.decomposition\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import sklearn.feature_selection\n",
    "import sklearn.metrics\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting regression in skl only supports single (1-d) targets.\n",
    "Choose the single target you'd like to explore here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output_columns = [\"Ca\",\"P\",\"pH\",\"SOC\",\"Sand\"]\n",
    "output_columns=[\"Ca\"]\n",
    "\n",
    "X,targets=load.load_training_spectra()\n",
    "\n",
    "y=targets[output_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees\n",
    "Gradient boosted trees can be regarded as the smarter older sibling to the [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor) ensemble method.\n",
    "Gradient Boosted Trees are iteratively corrected, with the residuals of the previous tree \n",
    "providing the basis for building the subsequent tree.  \n",
    "The user specifies the loss function to be optimized,\n",
    "and here we use least squares regression,\n",
    "the default loss function for scikit-learn's [GradientBoostingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html).\n",
    "More info and intuition about gradient boosted trees can be found [here](http://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help speed up the task of training these trees, \n",
    "we perform some dimensionality reduction \n",
    "and feature selection below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = skl.decomposition.PCA()\n",
    "X_transformed = pca.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = skl.model_selection.train_test_split(X_transformed,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn's **GradientBoostingRegressor** doesn't work for multiple targets, so we will train for one target at a time.  SKL does handle multioutput for instances like this with MultiOutputRegressor, but it seems to make info about the gradient boosting regressor less accessible (like feature importances).  For now we'll only look at one target, Ca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators=1000\n",
    "clf_Ca=skl.ensemble.GradientBoostingRegressor(n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time()\n",
    "clf_Ca.fit(X_train,y_train.values.ravel())\n",
    "print(\"GBR took %.2f seconds for %d estimators\"\n",
    "      % ((time() - start), n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf_Ca.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some scoring metrics for our first pass at this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl.metrics.mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl.metrics.r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are ways to save time without giving up model performance.  One way is by using GradientBoostingRegressor's **feature_importances** attribute, which can identify the most important features in determining a split, allowing us to cast out less important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we print out the highest ranking features\n",
    "(remember, these are the numbered labels of our Principal Components):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances=clf_Ca.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "#Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "#for f in range(X.shape[1]):\n",
    "for f in range(10):\n",
    "    print(\"{:d}.  feature {:d} ({:f})\".format(f+1,indices[f],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part, the important features appear to also correspond to the the PCs that explain the most variance.  \n",
    "However, one shouldn't read too much into the feature importances - \n",
    "a low rank does not necessarily mean that the feature isn't important in determining outputs, \n",
    "because there may be high correlation between features.  \n",
    "\n",
    "For more information, you can read [this post](http://alexperrier.github.io/jekyll/update/2015/08/27/feature-importance-random-forests-gini-accuracy.html) \n",
    "describing feature engineering and selection in random forests - \n",
    "most insights will apply to GBRTs as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(range(len(X_train)),\n",
    "        clf_Ca.feature_importances_[indices[range(len(X_train))]]/clf_Ca.feature_importances_[indices[0]])\n",
    "plt.xlabel('feature rank')\n",
    "plt.ylabel('feature importance (normalized to max)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick out the more important features to train on GradientBoostingRegressor again.  \n",
    "The reduction in dimensionality will allow us to explore the hyperparameter space in a more timely fashion.  \n",
    "Here we use skl's  **SelectFromModel**, and define a threshold above which we deem a feature important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm = skl.feature_selection.SelectFromModel(clf_Ca,threshold=0.002)\n",
    "sfm.fit(X_train,y_train.values.ravel()) #training the selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm.get_support(indices=True) #This array lists the feature indices identified as important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's transform our data to a subset that only includes the \"important\" features,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and train a new GBR with this curated feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_Ca_important=skl.ensemble.GradientBoostingRegressor(n_estimators=n_estimators)\n",
    "clf_Ca_important.fit(X_important_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find the mean squared error on our test subset, using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf_Ca.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl.metrics.mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find the mean squared error again, this time with only our selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_important_pred = clf_Ca_important.predict(X_important_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl.metrics.mean_squared_error(y_test,y_important_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing the number of features shouldn't increase the error much - error may even go down!  If error increased by an uncomfortable amount, try decreasing the feature_importance threshold to include more features.\n",
    "\n",
    "At this point one would usually use Randomized or Grid Search cross-validation \n",
    "to tune hyperparameters that optimize model performance.  This can be time-consuming,\n",
    "so some pre-determined hyperparameters are provided in the cell below\n",
    "if you're eager to immediately fit and examine a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators':3000,\n",
    "          'max_depth':3,\n",
    "          'min_samples_split':15,\n",
    "          'min_samples_leaf':3,\n",
    "          'max_features':0.8,\n",
    "          'learning_rate':0.01}\n",
    "clf_Ca_final = skl.ensemble.GradientBoostingRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_Ca_final.fit(X_important_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at our R-squared value on our test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_Ca_final.score(X_important_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the deviance at each stage (n_estimators total stages) for the training and test sets.  Each stage does appear to improve performance!  This seems true with most of our targets, with the exception of Phosphorus (P), which as of this writing has been difficult to fit with trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute test set deviance\n",
    "test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "\n",
    "for i, y_pred in enumerate(clf_Ca_final.staged_predict(X_important_test)):\n",
    "    test_score[i] = clf_Ca_final.loss_(y_test.values.ravel(), y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, clf_Ca_final.train_score_, 'b-',\n",
    "         label='Training Set Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n",
    "         label='Test Set Deviance')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('Deviance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearch cross-validation: when there's not enough time for GridSearch\n",
    "We used the feature_selection package to pare down our feature list to some important ones.  \n",
    "Now the **model_selection** package will help us to explore the hyperparameter space \n",
    "and pin down the right combination of hyperparameters that gives us the best model.  \n",
    "\n",
    "**GridSearchCV** loops through every combination of user-supplied lists of hyperparameters - \n",
    "with more than a few parameters, and more than a few values tried for each parameter, \n",
    "this can compound into a lot of iterations.  \n",
    "\n",
    "**RandomizedSearchCV** only calculates for randomly selected parameter sets, \n",
    "selected from user-supplied distribution functions (here listed in param_dist).  \n",
    "It can save a lot of time without too much degradation in performance. \n",
    "Distribution functions here come from the scipy.stats package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_cv = skl.ensemble.GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dist = {\"n_estimators\":sp_randint(50,200),\n",
    "              \"max_features\":sp_uniform(loc=0.4,scale=0.5),\n",
    "              \"min_samples_leaf\":sp_randint(1,20),\n",
    "              \"min_samples_split\":sp_randint(2,25),\n",
    "              \"max_depth\":sp_randint(2,8),\n",
    "              \"subsample\":sp_uniform(loc=.5,scale=.5),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iter_search=1000\n",
    "random_search=skl.model_selection.RandomizedSearchCV(clf_cv,\n",
    "                                                     param_distributions=param_dist,\n",
    "                                                     n_iter=n_iter_search,\n",
    "                                                     n_jobs=-1\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start=time()\n",
    "random_search.fit(X_important_train,y_train.values.ravel())\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d iterations\"\n",
    "      % ((time() - start), n_iter_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the info for the highest-ranking models.\n",
    "Hopefully a winning list of hyperparameters will emerge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report(random_search.cv_results_,n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve performance we can halve the learning rate and double n_estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If hand-tuning parameters is more your style, \n",
    "you can try a greedy cross-validation scheme, \n",
    "where hyperparameters are tuned and fixed one by one.\n",
    "\n",
    "A nicely laid out approach is outlined [here](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/).  \n",
    "The hyperparameters are tuned in a specific order, \n",
    "with the more important parameters appearing first:\n",
    "1. Tune an appropriate balance of n_estimators and learning_rate\n",
    "2. Tune tree parameters\n",
    "    a. max_depth and num_samples_split\n",
    "    b. min_samples_leaf\n",
    "    c. max_features\n",
    "3. Lower learning_rate as you increase n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
